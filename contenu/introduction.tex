\Introduction
\label{chap:introduction}

L'informatique graphique, branche du domaine de l'informatique, est l'étude de la création d'images numériques par ordinateur~\cite{poinssac_infographie_1994}. C'est un domaine à l'intersection de plusieurs disciplines, comme l'informatique, les mathématiques, la physique, l'optique, la biologie, et d'autres encore. L'informatique graphique trouve ses applications dans de nombreux autres domaines~\cite{ekaran_when_2021}, notamment celui du divertissement. Un défi de l'informatique graphique qui se dresse depuis ses débuts est celui de la création de contenu, car c'est un processus long et coûteux. Dans la figure~\ref{fig:hades} par exemple, le personnage, les bâtiments et leur architecture, la rivière et les effets de lumières sont tous des éléments qui ont dû être créés par une équipe d'artistes. Il existe diverses méthodes pour créer du contenu~\cite{juegoadmin_why_2023} dont plusieurs, comme le modelage 3D, qui demandent beaucoup de temps de travail aux artistes. De nos jours en particulier, il y a une demande croissante pour des univers virtuels de plus en plus grands et détaillés~\cite{imam_open_2022}. Les méthodes de création de contenu traditionnelles, par le pur travail manuel des artistes, sont de moins en moins viables en raison de la quantité de contenu nécessaire à créer pour remplir ces univers~\cite{freiknecht_survey_2017}. Il est nécessaire de mettre au point des méthodes plus automatisées pour permettre une création plus rapide et moins coûteuse.

\bigskip

\begin{figure}[!h]
    \centering
    \includegraphics[width=.85\textwidth]{contenu/resources/images/hades}
    \caption{{\it Hades} (2018), Supergiant Games~\cite{supergiant_hades_2018}}
    \label{fig:hades}
\end{figure}

Dans ce contexte de méthodes automatisées, la génération procédurale est un procédé utilisé pour produire toutes sortes de ressources numériques~\cite{smelik_survey_2014}. La génération procédurale est en particulier utilisée pour synthétiser l'apparence visuelle des différents composants des scènes virtuelles~\cite{alessio_procedural_2021}. En combinant des méthodes algorithmiques avec de l'aléatoire, il est possible de générer des cartes de texture qui servent à habiller les mondes virtuels. Une carte de texture désigne une image qui est appliquée sur une surface pour lui donner un aspect visuel dans le but d'accentuer l'immersion des utilisateurs. Différentes textures nécessitent différentes méthodes de synthèse pour être générées. Certains genres de textures sont encore difficilement réalisables avec les méthodes existantes~\cite{lutz_cyclostationary-gaussian_2021}. C'est dans cette perspective que s'inscrit ce travail de recherche, qui a pour but d'approfondir notre compréhension des éléments qui constituent la structure d'une image. Ce travail explore l'analyse multi-résolutionnelle locale et son application à la synthèse de texture procédurale. L'analyse multi-résolutionnelle locale est un outil du domaine du traitement du signal et est détaillée dans la suite de ce manuscrit au chapitre~\ref{chap:chapitre1}.

\section{Monde virtuel}

Dans le cadre de l'informatique graphique, un monde virtuel est une méthode de représentation de scènes au moyen d'un support numérique. Une scène est une collection d'objets numériques qui interagissent entre eux. Il existe trois sortes d'objets numériques qui composent une scène : de la géométrie, des lumières et des caméras. Avec des algorithmes dits de \og rendu \fg, un monde virtuel peut être converti en image. Les mondes virtuels sont utilisés dans de nombreux domaines~\cite{magnenat-thalmann_introduction_1986}, comme :

\begin{itemize}
    \item le domaine du divertissement, pour les jeux vidéo (l'industrie du jeu-vidéo est un des principaux acteurs des avancées en graphisme) ;
    \item le domaine de l'animation, pour les films d'animation ou les effets spéciaux de films ;
    \item le domaine médical, pour des outils de visualisation de l'anatomie humaine ou de formation en réalité virtuelle ;
    \item le domaine de l'ingénierie, pour aider à la conception d'objets (Conception Assistée par Ordinateur) ou de bâtiments (architecture) ;
    \item le domaine militaire, pour faire des simulations de situations ou des entraînements au combat.
\end{itemize}

\subsection*{Types de rendu}

La visualisation de scènes virtuelles s'opérationnalise au travers d'un logiciel dit \og moteur de rendu \fg utilisant divers algorithmes pour fonctionner~\cite{sherman_chapter_2003}. Un moteur de rendu traite une scène en différentes étapes dans le but de créer une visualisation de cette scène, appelée \og rendu de la scène \fg~\cite{pharr_physically_2023}. Il existe plusieurs méthodes de rendu qui implémentent différents algorithmes pour produire différentes visualisations d'une scène. Pour exécuter leurs calculs, les logiciels de rendu s'appuient sur les capacités des cartes graphiques ({\it Graphics Processing Unit} ou GPU). Les GPUs sont des processeurs hautement parallèles et spécialisés dès leur fabrication pour des calculs graphiques~\cite{das_history_2016}.

\bigskip

\begin{figure}[h]
    \centering
    \includegraphics[width=.65\textwidth]{contenu/resources/images/gollum}
    \caption[{\it Gollum} (2002), {\it Le Seigneur des Anneaux : Les Deux Tours}]{{\it Gollum}, personnage complètement généré par image de synthèse par rendu hors-ligne. {\it Le Seigneur des Anneaux : Les Deux Tours}, Peter Jackson~\cite{jackson_lord_2002}. Image par Mou~\cite{mou_keyframe_2018}.}
    \label{fig:gollum}
\end{figure}

Les méthodes de rendu peuvent être séparés en deux grandes catégories : le rendu \og hors-ligne \fg et le rendu \og en temps-réel \fg. Le rendu hors-ligne désigne les algorithmes qui font la visualisation de scènes non interactives, où il n'est pas possible de contrôler les interactions entre les éléments de la scène. Les films d'animation ou les effets spéciaux de films~\ref{fig:gollum} sont des exemples de rendus fait hors-ligne. L'utilisation de méthodes de rendu hors-ligne est en fait devenu une norme dans l'industrie cinématographique~\cite{media_history_2021}, car elle permet la création de scènes qu'il serait impossible de tourner à l'aide de caméras traditionnelles. À l'inverse, lors d'un rendu en temps-réel, une personne utilisatrice a un contrôle sur la scène qui est rendue pendant qu'elle est rendue. Le déplacement d'un personnage dans un jeu-vidéo, la manipulation d'un modèle de pont dans un logiciel d'architecture et l'affichage d'objets dans une application de réalité augmentée sont tous des exemples de rendus en temps-réel. Une même scène peut être rendue avec plusieurs méthodes de rendu, la visualisation finale sera alors différente à chaque fois. Une scène rendue en temps-réel d'une part et hors-ligne d'autre part, est montrée à la figure~\ref{fig:zero-day}. Les enjeux et contextes des rendus hors-ligne et en temps-réel diffèrent. Le travail présenté dans ce manuscrit s'intéresse aux méthodes de rendu en temps-réel. Dans la méthode proposée, bien qu'une partie de préparation des données soit nécessaire, le rendu final se fait en temps-réel. Les problématiques et solutions concernant le rendu hors-ligne ne sont donc pas abordées dans ce travail.

\bigskip

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{contenu/resources/images/zero_day_comparison}
    \caption[{\it Zero-Day} (2015), BEEPLE]{{\it Zero-Day} (2015), BEEPLE. À gauche rendu original hors-ligne, à droite rendu temps-réel par SY tracé de chemins, NVIDIA~\cite{ZeroDay}}
    \label{fig:zero-day}
\end{figure}

Une méthode de rendu en temps-réel doit répondre à certaines contraintes dues à la nature interactive de la scène. Le rendu de la scène ne peut pas se faire en avance, car la scène est modifiée pendant l'utilisation. Le rendu doit être assez rapide pour afficher les images assez vite de telle sorte que le flux soit continu à l'œil humain. L'industrie cinématographique utilise un standard de 24 images par secondes pour l'enregistrement de films~\cite{deguzman_why_2023}. Pour un rendu en temps-réel, les applications visent des objectifs d'au moins 30 ou 60 images par secondes, afin que le contrôle utilisateur soit confortable~\cite{janzen_is_2014}. Les algorithmes utilisés doivent ainsi être conçus pour s'exécuter avec moins de temps, moins de ressources de calcul, et moins d'espace mémoire disponible.

\subsection*{Maillage}

Pour manipuler une scène virtuelle, il est nécessaire d'avoir une représentation des éléments qui la composent. Une représentation est une manière technique de décrire et stocker les données d'une scène. Il y a deux façons de représenter une géométrie dans un monde virtuel. Les représentations continues, comme les surfaces implicites, se rapprochent au mieux des formes des objets du monde réel, mais sont difficiles à créer. Les représentations discrètes, comme les maillages, approximent les représentations continues par des ensembles de polygones~\cite{coons_surfaces_1967}, souvent des triangles. Les polygones qui forment un maillage sont définis explicitement par des données géométriques, notamment les positions des sommets et les sommets des faces. La figure~\ref{fig:procedural-mesh} montre les polygones qui composent un modèle de terrain. Dans ce travail, seuls les maillages seront utilisés. Les maillages sont des structures habituelles dans les mondes virtuels.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{contenu/resources/images/full_terrain}
    \caption{Maillage d'un terrain généré procéduralement}
    \label{fig:procedural-mesh}
\end{figure}

\section{Texture}

\subsection*{Plaquage de texture}

Le maillage utilisé pour représenter une géométrie est une approximation. Pour affiner la géométrie, ou lui attribuer une apparence, il est possible d'utiliser des \og textures \fg. Une texture est une fonction d'un espace de coordonnées, habituellement à deux ou trois dimensions, à valeurs dans un espace quelconque qui représente les différents attributs possibles de la texture. Les dimensions de l'espace d'arrivée sont appelées \og canaux \fg de la texture. Les textures représentent généralement la couleur d'une surface, ou d'autres grandeurs physiques comme la profondeur ou l'élévation, qui servent au rendu de la géométrie à laquelle est associée la texture. En fonction du modèle de rendu choisi pour la scène, différentes textures sont nécessaires. Le format de rendu physique réaliste ({\it Physically Based Rendering} ou PBR), standard de l'industrie~\cite{hoffman_siggraph_2010}, nécessite typiquement cinq cartes de texture~\cite{pharr_physically_2023} : l'albedo (ou couleur), mais aussi la normale, la hauteur, la rugosité et l'occlusion ambiante.

\bigskip

\begin{figure}
    \centering
    \includegraphics[width=.65\textwidth]{contenu/resources/images/mutli-material-object}
    \caption[Rendu d'un objet comportant plusieurs matériaux]{Plusieurs matériaux différents sont utilisés pour le rendu de cet objet~\cite{fig:multi-material}}
    \label{fig:multi-material}
\end{figure}

La méthode de travail usuelle en industrie consiste à regrouper ces différentes textures, ainsi que le modèle d'éclairage, dans une ressource dite \og matériau \fg. Les objets d'une scène sont composés de plusieurs matériaux, qui présentent chacun des propriétés physiques différentes. Dans la figure~\ref{multi-material} par exemple, la lunette a un harnais en cuir, un objectif en métal et des lentilles en verre. Pour créer leurs scènes, les artistes façonnent leurs objets en commençant par la géométrie, avant de créer (ou réutiliser) différents matériaux pour habiller leurs objets.

\bigskip

Il existe deux méthodes classiques de stockage pour une texture : procédurale ou discrète. Une texture procédurale est représenté sous une forme fonctionnelle, à l'aide d'équations ou de procédures. Une texture discrète, quant à elle, est stockée comme une image numérique, c'est-à-dire un tableau discret et fini de données. La représentation procédurale, dont un exemple est donné à la figure~\ref{fig:perlin-noise}, présente plusieurs avantages par rapport à la représentation discrète :

\begin{itemize}
    \item la compacité : pour stocker une texture procédurale, il suffit de stocker les fonctions ou chaines d'instructions qui la définissent. Une texture procédurale n'occupe donc que très peu d'espace en mémoire.
    \item la taille : une texture procédurale est définie comme une fonction sur un espace de paramètre. Une texture procédurale est donc intrinsèquement infinie.
    \item la résolution : une texture procédurale est une fonction continue au sens mathématique. Il est possible de connaître la valeur exacte d'une texture procédurale en n'importe quel point de l'espace de coordonnées en l'évaluant en ce point.
\end{itemize}

Les textures procédurales ont cependant des désavantages. Certaines apparences souhaitées sont difficilement exprimables de manière fonctionnelle. Une expression fonctionnelle peut aussi être difficile à manipuler pour des artistes, puisqu'il faut ajuster des paramètres et modifier l'apparence de manière indirecte. De plus, l'expression d'une texture procédurale est parfois complexe et peut être un enjeu pour la synthèse en temps-réel. Il arrive que la fonction ou suite d'instructions qui définissent une texture procédurale sont si longs à exécuter que le budget de temps pour le rendu de l'image est dépassé. Une texture qui fait dépasser le budget temps du rendu n'est pas viable.

\bigskip

\begin{figure}[h]
    \centering
    \includegraphics[width=.5\textwidth]{contenu/resources/images/perlin-noise}
    \caption[Bruit de Perlin]{La notion de texture procédurale est introduite par Ken Perlin en 1985 avec son bruit de Perlin~\cite{perlin_image_1985}.}
    \caption{fig:perlin-noise}
\end{figure}

Résoudre les problématiques des textures procédurales est un enjeu de l'informatique graphique. Obtenir de nouvelles apparences, avoir un meilleur contrôle par les artistes et une évaluation plus rapide sont des sujets constamment explorés dans le domaine~\cite{heitz_high-performance_2018, tricard_procedural_2019, lutz_cyclostationary-gaussian_2021, baldi_differentiable_2023}. Le sujet présenté dans ce manuscrit s'inscrit dans la problématique de l'agrandissement du champ des apparences représentables par texture procédurale.

\subsection*{Échantillonnage}

Le processus utilisé traditionnellement pour le rendu en temps-réel est appelé le \og \textit{pipeline} graphique de rastérisation \fg. Dans ce \textit{pipeline}, la scène rendue est projetée sur le plan image, qui est une représentation virtuelle de l'écran. La géométrie est ensuite divisée en petits éléments de surface appelés \og fragments \fg, durant l'étape éponyme de \og rastérisation \fg. La figure~\ref{fig:rasterization} montre comment un triangle est rastérisé dans le \textit{pipeline} traditionnel. Les fragments sont les éléments atomiques du \textit{pipeline} de rastérisation : ce sont les plus petits éléments indivisibles manipulés. Au terme du processus de rendu, un fragment est soit défaussé car non visible dans l'image finale, soit donné une couleur et affiché. Un fragment affiché à l'écran est appelé un \og pixel \fg (mot-valise de \textit{Picture Element}). L'ensemble des pixels forme l'image rendue.

\begin{figure}[h]
    \centering
    \includegraphics[width=.55\textwidth]{contenu/resources/images/rasterization}
    \caption[Rastérisation d'un triangle]{Un triangle (rouge) rastérisé (noir). Crédit à Wojciech mula pour l'image.}
    \label{fig:rasterization}
\end{figure}

\bigskip

\begin{figure}
    \centering
    \includegraphics[width=.55\textwidth]{contenu/resources/images/uv_suzanne}
    \caption[Coordonnées UV du modèle Suzanne]{Visualisation des coordonnées UV de Suzanne~\cite{suzanne-uv}, modèle 3D de référence du logiciel Blender}
    \label{fig:uv-suzanne}
\end{figure}

Pour appliquer une texture à une géométrie, un système de coordonnées, dites \og coordonnées UV \fg, est utilisé. Les coordonnées UV sont des vecteurs 2D, entre $(0, 0)$ et $(1, 1)$. Les sommets des maillages des objets de la scène ont chacun des coordonnées UV, qui leurs sont associées à la création de l'objet. Les coordonnées UV sont ensuite interpolées entre les sommets lors de la rastérisation. Les fragments ont ainsi chacun des coordonnées UV. Un exemple de rendu exhibant les coordonnées UV d'un modèle 3D est montré à la figure~\ref{fig:suzanne}. Les coordonnées UV indiquent quelles parties de la texture correspondent à chaque fragment de la géométrie. L'action d'évaluer une texture en utilisant les coordonnées UV des fragments est appelée \og échantillonnage \fg de la texture. Ce processus d'échantillonnage s'effectue en général au moment du rendu.

\subsection*{Filtrage}
\label{subsec:filtering}

L'étape d'échantillonnage comporte un problème inhérent, dû au fonctionnement d'un écran et à la nature discrète du système de pixels. Comme expliqué, la géométrie de la scène est projetée, puis découpée en fragments. Le fragment représente donc une partie de surface continue. Mais un fragment est un élément discret, il ne prend qu'une seule valeur. Le schéma en figure~\ref{fig:aliasing} illustre cette problématique. Avec les notations de la figure, un fragment $P$ représente la surface projetée $e(P)$ avec une seule valeur. La valeur que devrait prendre le fragment est l'intégrale de la texture sur l'empreinte $e(P)$. Cette valeur est cependant difficile à calculer dans la majorité des cas. Dans le cas de textures discrètes, une considération supplémentaire doit être faite. L'empreinte du fragment sur la surface texturée est souvent de taille différente que le texel (mot-valise de \textit{Texture Element}) de la texture.

\bigskip

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{contenu/resources/images/schema_filtrage}
    \caption[Visualisation du problème d'échantillonnage lors du rendu par rastérisation]{À cette distance de l'écran, l'empreinte $e(P)$ du fragment sur la surface texturée couvre plusieurs texels. Les coordonnées $(u, v)$ ne sont pas suffisantes pour capturer toute l'information de la texture.}
    \label{fig:aliasing}
\end{figure}

Les comportements indésirables causés lors des étapes de rendu et observables sur l'image finale sont appelés \og artefacts de visualisation \fg. Dans le cas de l'échantillonnage, les artefacts causés par la différence de taille entre un fragment et son empreinte sur une surface texturée sont appelés artefacts d' \og aliassage \fg. Pour résoudre les problèmes d'aliassage, plusieurs méthodes dites de \og filtrage \fg sont utilisées, dépendamment du problème d'aliassage rencontré :

\begin{itemize}
    \item le \og sur-échantillonnage \fg signifie que l'empreinte d'un fragment est plus petite qu'un texel. En cas de sur-échantillonnage, plusieurs fragments voisins peuvent prendre la même valeur. Avoir une même valeur pour plusieurs fragments voisins donne un aspect crénelé à l'image et les contours des objets sont en escalier. La solution idéale dans ce cas est d'augmenter la résolution de la texture utilisée ; ce n'est cependant pas tout le temps possible. Une alternative commune est de faire l'interpolation des valeurs des quatre texels voisins. La texture est échantillonnée quatre fois pour chaque fragment et l'image prend un aspect légèrement flouté, mais l'effet escalier est réduit. Un exemple est montré à la figure~\ref{fig:filtering}
    \item le \og sous-échantillonnage indique que l'empreinte d'un fragment est plus grande qu'un texel et en recouvre plusieurs, comme à la figure~\ref{fig:aliasing}. En cas de sous-échantillonnage, des fragments voisins représentent du contenu éloigné spatialement sur la surface. La surface entre les centres des empreintes de fragments voisins est alors mal représentée. De loin, la surface texturée présente des motifs dits de \og moiré \fg. Des bandes non-présentes dans la texture apparaissent sur le rendu et il y a un effet de scintillement lorsque la caméra est déplacée dans la scène. L'apparence souhaitée est l'intégrale des texels qui sont sous l'empreinte du fragment, mais un algorithme de rastérisation naïf ne lit qu'un seul texel. La solution idéale serait de calculer l'intégrale sur tous les texels couverts par l'empreinte du fragment. Calculer l'intégrale directement est souvent irréalisable. L'approche traditionnelle dite \og filtrage tri-linéaire \fg consiste à pré-calculer une approximation de l'intégrale pour différentes tailles d'empreintes et trouver le bon niveau au moment du rendu. Cette approche double l'occupation mémoire pour chaque texture, mais les effets de moiré disparaissent.

%    \item Différentes résolution des textures utilisées appelées \og MIPs maps \fg sont pré-calculées avant le rendu. Ces MIPs maps sont l'approximation des intégrales de régions de texels de différentes tailles. La technique de filtrage dit \og tri-linéeaire \fg consiste à trouver les niveaux adéquats de MIPs maps auquel l'empreinte du fragment a une taille similaire à un texel. L'échantillonnage de la texture se fait alors dans les deux niveaux les plus proches.
%    \item L'alternative classique consiste à pré-calculer différentes échelles de la texture utilisée, appelées \og MIP maps \fg, et de trouver l'échelle adéquate de telle sorte qu'un texel ait la même taille qu'un fragment. L'échantillonnage est plus lourd et on prend plus d'espace mémoire pour stocker les MIP maps, mais la texture est mieux rendue de loin.
\end{itemize}

\bigskip

\begin{figure}
    \centering
    \begin{subfigure}[b]{.45\textwidth}
        \includegraphics[width=\textwidth]{contenu/resources/images/porcelain_no_filter}
        \caption{Sans filtrage}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{.45\textwidth}
        \includegraphics[width=\textwidth]{contenu/resources/images/porcelain_filter}
         \caption{Avec filtrage linéaire}
     \end{subfigure}
    \caption{Filtrer correctement est un enjeu majeur dans l'utilisation des textures}
    \label{fig:filtering}
\end{figure}

S'assurer de filtrer correctement lors de l'échantillonnage est un enjeu majeur pour obtenir un rendu fidèle aux textures utilisées. C'est particulièrement le cas lors la création de textures procédurales, qui est le sujet de cette étude. Diverses méthodes peuvent être utilisées pour la création de textures procédurales. S'assurer de la filtrabilité d'une méthode de création de textures est une des problématiques principales et un critère de qualité de la synthèse de texture, présentée dans la section suivante.

%{\color{red}Pertinence de ce paragraphe ?}
%De nombreuses méthodes de filtrage plus élaborées sont employées pour obtenir des résultats de meilleure qualité, ou pour filtrer des textures plus compliquées. Par exemple quand les textures ne sont plus des images prédéterminées à l'avance, mais qu'elles sont générées au moment du rendu.
% oui pertinent, mentionner les autres solutions "idéales" mais plus difficiles (voir not). filtre analytique et pré-intégration
%OU p-e supprimer paragraphe

\section{Synthèse de texture}

De nombreuses surfaces texturées lors d'un rendu, comme des sols, sont de grande taille. Comme discuté précédemment~\ref{subsec:filtering}, produire des textures de résolution suffisante pour texturer de grandes surfaces sans artefacts demande une grande occupation mémoire et un long temps de création. Étirer les textures en utilisant les coordonnées UV est une solution, qui atteint cependant ses limites assez rapidement. Utiliser une texture de plus basse résolution cause des artefacts visuels. Il est possible de résoudre le problème en créant directement une texture de taille adaptée à la surface à couvrir, procédé appelé \og synthèse de texture \fg. Par extension, une texture générée par un algorithme de synthèse est aussi appelée une synthèse. Les textures représentent des apparences visuelles de matériaux diverses. Il est possible de classifier des textures de plusieurs manières différentes. Une façon commune de classifier des textures est d'opposer les textures stochastiques, dont les couleurs de pixels semblent aléatoires, et les textures régulières, qui présentent une répétition régulière de motifs~\cite{lieu_near-regular_2004}.

\bigskip

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{contenu/resources/images/structure_scale}
    \caption[Classification des textures selon leur niveau de structure]{Les textures peuvent être classées selon leur niveau de structure : stochastiques ou gaussiennes (gauche), semi-régulières (milieu), ou structurées (droite)}
    \label{fig:échelle-structure}
\end{figure}
% TODO changer image de droite, confusant avec périodicité

Le travail présenté dans ce manuscript s'intéresse cependant à la synthèse de texture présentant de la structure. Le concept de structure, bien qu'intuitif, est difficile à définir de manière formelle. Dans le cadre de ce manuscript, la \og structure \fg d'une texture désigne comment les différentes parties de la structure sont agencées les unes par rapport aux autres. Dans une texture structurée, les éléments de la texture forment certains schémas ou présentent une certaine forme de régularité. La classification de textures utilisée dans ce travail est faite selon le niveau de structure des textures car c'est le thème central de l'étude. La figure~\ref{fig:échelle-structure} illustre la classification proposée.

\subsection*{Algorithme de synthèse}

Une synthèse de texture un procédé qui permet de produire une texture de taille arbitraire, pouvant prendre en argument des paramètres de différente nature. Différentes synthèses possèdent différentes propriétés, qui peuvent être voulues ou non en fonction de la scène à rendre. Par exemple la texture générée est souvent infinie, il est possible de l'appliquer à des surfaces de taille quelconque avec la résolution désirée. De plus, la texture est évaluée au vol (pendant le rendu) et n'a pas besoin d'être stockée en mémoire. Cela réduit l'occupation mémoire de la texture.

\bigskip

Il existe plusieurs types de synthèses différentes, qui produisent des types de textures différentes. Une première distinction majeure qui est souvent faite est, comme pour le rendu, entre une synthèse hors-ligne et une synthèse en temps réel. Les ressources en temps et en puissance de calcul impliquées diffèrent, les enjeux ne sont pas les mêmes. Les travaux proposés étudient le rendu et la synthèse temps-réel, les synthèses hors-lignes comme les synthèses par optimisation ou par apprentissage profond ne seront pas abordées. Les algorithmes étudiés ici ont la contrainte de devoir s'exécuter au vol, sans que le budget de temps du rendu dépasse le seuil établi. Pour rentrer dans ces contraintes de temps, les méthodes de synthèse exploitent la puissance des GPUs, notamment leur aspect hautement parallélisable. Les algorithmes de synthèse doivent s'exécuter de manière parallèle et chaque fragment doit se calculer indépendamment de ses voisins.

\subsection*{Synthèse temps-réel} % / Types de synthèse

Sous ces contraintes d'efficacité et de rapidité, de nombreux algorithmes subsistent ; deux grandes catégories de méthodes courantes sont la synthèse \og par réorganisation \fg et la synthèse \og par convolution \fg.

\subsubsection{Synthèse par réorganisation}

Le but d'une synthèse par réorganisation est de reproduire un extrait de texture donné en entrée en réutilisant et réagençant son contenu. Dans une synthèse par réorganisation, le contenu est découpé en petites régions connexes dites « tuiles ». Plusieurs paramètres comme la taille, forme et disposition des tuiles peuvent être modifiés pour varier la synthèse. L'exemple le plus simple de synthèse par réorganisation est le pavage périodique. Dans un pavage périodique, la texture d'entrée est simplement répétée jusqu'à couvrir la surface désirée. Pour pouvoir faire un pavage périodique, il faut que la texture d'entrée soit périodique, c'est-à-dire qu'elle se répète sans coupure. Le pavage périodique, bien que très rapide, est de faible qualité. Des artefacts visuels sont induits, car il n'y a aucune variation au sein de la texture générée et les motifs sont répétés très régulièrement. Quelques exemples d'artefacts visuels causés par un pavage périodique sont montrés à la figure~\ref{fig:periodic-tiling}. Certains motifs dits \og saillants \fg sont particulièrement visibles et attirent l'œil, à cause de leur couleur ou de leur forme par exemple. La répétition régulière de motifs saillants n'existe en général pas dans la nature, elle attire encore plus le regard d'une personne observatrice et réduit la sensation d'immersion dans la scène.

\bigskip

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{contenu/resources/images/periodic_tiling}
    \caption[Artefacts d'alignement créés par le pavage périodique]{Artefacts d'alignement créés par le pavage périodique, \textit{Monster Hunter Rise} (2021), Capcom. Crédit à N. Lutz~\cite{lutz_processus_2021} pour l'image.}
    \label{fig:periodic-tiling}
\end{figure}

La gestion de l'équilibre entre cohérence et variété est un enjeu majeur dans la synthèse par réorganisation. La cohérence qualifie comment la synthèse reproduit l'apparence visuelle de l'exemple. La variété est la capacité à générer de la nouveauté dans le contenu généré. L'objectif de la synthèse est de propager une apparence similaire à l'exemple sur une grande surface, comme si l'apparence entière avait été synthétisée directement par un unique procédé. Une bonne synthèse doit ainsi apporter à la fois de la cohérence et de la variété. Le pavage périodique par exemple est très cohérent, mais n'apporte aucune variété. Dans un pavage périodique, la tuile qui est réagencée est en fait la texture entière.

\bigskip

Le faible qualité du pavage périodique illustre l'importance du choix de la taille de tuile dans la gestion de l'équilibre entre cohérence et variété. Une grosse tuile capture bien l'apparence de la texture, mais reproduit des motifs saillants qui causent des artefacts et n'offrent pas beaucoup de variété. À l'inverse avec une petite tuile, seulement quelques texels sont réutilisés et certaines relations entre texels éloignés sont perdues, ce qui cause une perte de cohérence. Il est préférable de prendre des tuiles plus petites et mieux les mélanger~\cite{heitz_high-performance_2018} afin de d'obtenir de la variété et d'éviter la répétition de motifs saillants.


\subsubsection{Synthèse par convolution}

% TODO def noyaux
L'objectif d'une synthèse par convolution est de construire une texture en disposant des motifs, appelés \og noyaux \fg, selon une distribution statistique. Le choix du noyau, de la distribution, ainsi que de la méthode de mélange, sont les paramètres à ajuster pour contrôler la synthèse. Une pratique habituelle de la synthèse par convolution est de choisir comme noyau une somme d'ondelettes (typiquement des cosinus) spatialement contraintes et à orientation aléatoire, et de contrôler les fréquences des ondelettes utilisées~\cite{tricard_procedural_2019}. En sélectionnant les fréquences, on a un contrôle sur le contenu fréquentiel présent dans la texture produite, ce qui permet une bonne maîtrise de l'apparence générée~\cite{gilet_local_2014}.
% Tu peux illustrer avec le LRPN de Guillaume. N'hésite pas à fouiller dans mon manuscrit de thèse sinon.


\bigskip

% DIRE QUE LA SYNTHESE DE MOTIFS OU DE STRUCTURE EST ENCORE TRES COMPLIQUEE
Les méthodes existantes de synthèse ne fonctionnent cependant pas bien lorsque la cible contient des motifs organisés ou de la répétition. Quelques tentatives ont été faites~\cite{lutz_cyclostationary-gaussian_2021} pour synthétiser des textures présentant une forme de structure et régularité, mais en dehors de configurations présentant des caractéristiques particulières, comme une certaine périodicité, la synthèse de structure irrégulière est compliquée.
% TODO image pour appuyer dernière ligne + mieux expliquer pourquoi
% TODO contribution \cite à décrire. Tu peux aussi citer l'article sur la préservation de l'autocovariance

% \section{Génération procédurale} % Non-nécessaire ? De quoi on parle ici sinon ?

% \section{Bruit procédural}

\section{Analyse multi-résolutionnelle locale}

Une des raisons pour lesquelles la synthèse de texture contenant de la structure est difficile est qu'il faut préserver certaines relations entre les texels de l'image pour garder la structure. Savoir quelles relations préserver, pour garder la structure de l'image, et quelles relations supprimer, pour ajouter de la variation dans la synthèse, est très délicat, surtout dans le contexte du temps-réel. L'idée explorée dans cette recherche est d'appliquer des outils de l'analyse d'image, outils capables d'extraire des caractéristiques d'une image par l'analyse de relations intra-image, à des processus de synthèse.
% TODO question à soulever plutôt qu'affirmation à faire
% qu'est ce qu'une structure ? mieux introduire avec la partie d'après
% TODO Suggestion : parler de "relations statistiques" plutôt que de "relations", et dire qu'il faut les préserver au mieux. Tu veux préserver toutes les relations statistiques, mais certaines sont trop complexes à préserver en temps réel, en plus d'être difficiles à "capturer". C'est pour ça que tu essayes de développer les outils suivants.
% TODO très délicat = trop vague

\subsection*{Notion de structure}

La structure d'une image désigne comment les différentes parties de l'image sont agencées les unes par rapport aux autres, comment les éléments de l'image forment certains schémas ou présentent une certaine forme de régularité. Ces relations sont présentes à différents niveaux d'échelle, on a donc différents niveaux de structure. Savoir quels niveaux préserver et comment est important pour reproduire les caractéristiques désirées de la texture.

\begin{figure}[h!]
    \centering
    \includegraphics[width=.85\linewidth]{contenu/resources/images/structure_level}
    \caption{Différents niveaux de structure au sein d'une image}
    \label{fig:structure_level}
\end{figure}

\subsection*{Congruence de phases}

Lorsque l'on veut préserver la structure d'une image, les éléments saillants tels que des coins et des lignes, ou plus généralement des bords, sont compliqués à reproduire. On appelle \og bord \fg une région frontière entre un objet et un autre élément de l'image, comme l'arrière plan ou un autre objet. Visuellement, un bord se distingue par un changement brusque de luminosité. Ces changements sont cependant plus difficiles à détecter automatiquement, car le seuil minimum de contraste entre des pixels voisins n'est pas toujours le même, dépendamment de si le bord est franc ou flou. Une approche intéressante est d'utiliser des informations du domaine fréquentiel pour caractériser des bords.
% TODO /!\ luminosité terme nouveau à mieux definir
% p-e image pour illustrer
% TODO "compliqué à reproduire" pourquoi ?
% TODO source pour utilisation domaine fréquentiel

\bigskip

Lorsqu'une image est décomposée dans le domaine de Fourier, on retrouve de nombreuses informations sur la structure dans la phase~\cite{oppenheim_importance_1981}. En explorant le rôle de la phase, Kovesi a mis au point un outil de détection de d'éléments caractéristiques~\cite{kovesi_image_1995} basé sur le modèle physiologiquement réaliste d'énergie locale de Morrone et al.~\cite{morrone_feature_1987, morrone_feature_1988}. Ce modèle postule que les éléments caractéristiques sont présents dans une image là où les composants de Fourier sont maximalement en phase. La congruence de phases qui dérive du modèle d'énergie locale est une grandeur qui quantifie cet alignement. Elle donne lieu à un outil de détection plus robuste que ceux développés auparavant, qui sont souvent sensibles au niveau d'illumination et de grossissement, et nécessitent donc une connaissance a priori des images étudiées. C'est ce modèle de congruence de phases que nous avons repris et adapté à la synthèse de texture.
% TODO paragraphe trop rapide
% étendre et reposer la problématique
% notamment vis a vis de l'aléatoire, préserver congruence avec aléatoire est le noeud du pbl
% todo introduire PC avant de juste en parler

\bigskip

\begin{figure}[h]
    \centering
    \includegraphics[width=.35\linewidth]{contenu/resources/images/pc_1d_kovesi}
    \caption[Congruence de phases pour un signal 1D]{Congruence de phases pour un signal 1D, Kovesi (1995)~\cite{kovesi_image_1995}}
    \label{fig:pc_1d_kovesi}
\end{figure}

Pour détecter un alignement de phase, il est nécessaire d'avoir un modèle donnant des informations locales sur notre image. Kovesi utilise pour cela une banque de filtres à orientation variable. Nous utilisons à la place le modèle mathématique de la transformée de Riesz, qui permet de décomposer une image dans un espace différent, similairement à la transformée de Fourier, mais avec des informations locales, au niveau du texel (on rappelle que la transformation de Fourier fournit des informations fréquentiellement locales, mais spatialement globales). Utiliser cette transformée nous permet ainsi d'étudier la présence et préservation de relations dans un autre espace que le domaine spatial, donc de mieux comprendre et caractériser nos images.
% TODO dernière ligne : comment pourquoi dans quel but pour atteindre quoi ?

\subsection*{Analyse multi-échelle}

% TODO première phrase : pourquoi ? répond a quel besoin ?
Un objectif de la méthode présentée ici est de pouvoir agir avec précision sur certains niveaux d'échelle de structure ciblés. Une méthode d'analyse qui permet de travailler avec plusieurs niveaux de résolution de la même image est dite \og multi-résolutionnelle \fg~\cite{mallat_theory_1989}, ou multi-échelle. Des exemples d'application communs de méthodes d'analyse multi-résolutionnelle sont la détection robuste de caractéristiques de différentes tailles~\cite{park_multiresolution_2010} et la compression d'images~\cite{averbuch_image_1996}.
%TODO étendre et mieux expliquer. intégrer la phrase d'après qui a été coupée du texte
On décompose notre image en pyramide d'images, ce qui nous permet d'étudier les différences de détails entre les différents niveaux d'échelle.

\section{Plan du manuscript} % / problématique

Ce manuscrit est organisé comme suit :

\begin{itemize}
%    \item revue de l'état de l'art de la synthèse de texture temps réel,
    \item explication de la théorie de Riesz et du modèle d'analyse multi-échelle local qui en découle,
    \item application à la synthèse de texture par échantillonnage préférentiel.
\end{itemize}